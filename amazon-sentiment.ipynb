{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":800230,"sourceType":"datasetVersion","datasetId":1305},{"sourceId":10479620,"sourceType":"datasetVersion","datasetId":6489054}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":25473.102831,"end_time":"2023-06-22T07:19:58.848664","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-06-22T00:15:25.745833","version":"2.4.0"},"colab":{"name":"Brain MRI generation using WGAN-GP","provenance":[],"gpuType":"V28"},"accelerator":"TPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hvvsathwik/amazon-sentiment?scriptVersionId=220100964\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install fireducks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:39:06.040638Z","iopub.execute_input":"2025-01-26T12:39:06.040999Z","iopub.status.idle":"2025-01-26T12:39:10.102496Z","shell.execute_reply.started":"2025-01-26T12:39:06.04097Z","shell.execute_reply":"2025-01-26T12:39:10.101315Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: fireducks in /usr/local/lib/python3.10/dist-packages (1.1.8)\nRequirement already satisfied: firefw==1.1.8 in /usr/local/lib/python3.10/dist-packages (from fireducks) (1.1.8)\nRequirement already satisfied: pandas<2.3.0,>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from fireducks) (2.1.4)\nRequirement already satisfied: pyarrow<18.2,>=18.1 in /usr/local/lib/python3.10/dist-packages (from fireducks) (18.1.0)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.5.3->fireducks) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.5.3->fireducks) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.5.3->fireducks) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.5.3->fireducks) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=1.5.3->fireducks) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# For data manipulation and analysis\nimport fireducks.pandas as pd  # Using FireDucks for faster DataFrame operations\n\n# For text preprocessing\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# For feature extraction\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# For model training and evaluation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Download necessary NLTK data\nnltk.download('punkt')\nnltk.download('stopwords')\n","metadata":{"id":"RAqROHmQZp-d","outputId":"2a5327c4-607d-4e14-96af-363641963b3e","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T16:22:14.206806Z","iopub.status.idle":"2025-01-24T16:22:14.207117Z","shell.execute_reply":"2025-01-24T16:22:14.206987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to the training file\nfile_path = '/kaggle/input/amazonreviews/train.ft.txt.bz2'\n\n# Read the compressed file\ndata = pd.read_csv(file_path, sep='\\t', header=None, names=['text'], compression='bz2')\n\n# Inspect the dataset\nprint(\"Dataset Preview:\")\nprint(data.head())\nprint(f\"Total records: {len(data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T16:22:18.983389Z","iopub.execute_input":"2025-01-24T16:22:18.983657Z","iopub.status.idle":"2025-01-24T16:23:55.958287Z","shell.execute_reply.started":"2025-01-24T16:22:18.983637Z","shell.execute_reply":"2025-01-24T16:23:55.957407Z"}},"outputs":[{"name":"stdout","text":"Dataset Preview:\n                                                text\n0  __label__2 Stuning even for the non-gamer: Thi...\n1  __label__2 The best soundtrack ever to anythin...\n2  __label__2 Amazing!: This soundtrack is my fav...\n3  __label__2 Excellent Soundtrack: I truly like ...\n4  __label__2 Remember, Pull Your Jaw Off The Flo...\nTotal records: 3600000\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Extract labels and reviews from the text\ndata['label'] = data['text'].str.extract(r'__label__(\\d)').astype(int)\ndata['review_text'] = data['text'].str.replace(r'__label__\\d ', '', regex=True)\n\n# Map labels into three categories (1 = Negative, 2 = Positive, 3 = Neutral if present)\nlabel_mapping = {1: \"Negative\", 2: \"Positive\", 3: \"Neutral\"}\ndata['label'] = data['label'].map(label_mapping)\n\n# Retain only relevant columns\ndata = data[['review_text', 'label']]\n\n# Preview the cleaned data\nprint(\"Cleaned Dataset Preview:\")\nprint(data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T16:23:59.760731Z","iopub.execute_input":"2025-01-24T16:23:59.761047Z","iopub.status.idle":"2025-01-24T16:24:11.691329Z","shell.execute_reply.started":"2025-01-24T16:23:59.76102Z","shell.execute_reply":"2025-01-24T16:24:11.690458Z"}},"outputs":[{"name":"stdout","text":"Cleaned Dataset Preview:\n                                         review_text     label\n0  Stuning even for the non-gamer: This sound tra...  Positive\n1  The best soundtrack ever to anything.: I'm rea...  Positive\n2  Amazing!: This soundtrack is my favorite music...  Positive\n3  Excellent Soundtrack: I truly like this soundt...  Positive\n4  Remember, Pull Your Jaw Off The Floor After He...  Positive\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Display class distribution\nclass_counts = data['label'].value_counts()\nprint(\"Class Distribution:\")\nprint(class_counts)\n\n# Plot class distribution\nclass_counts.plot(kind='bar', title='Class Distribution')\nplt.xlabel('Labels')\nplt.ylabel('Counts')\nplt.xticks(rotation=0)  # Optional: Rotate x-axis labels to avoid overlap if needed\nplt.show()  # Ensure this is called to display the plot\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T16:26:12.567212Z","iopub.execute_input":"2025-01-24T16:26:12.567543Z","iopub.status.idle":"2025-01-24T16:26:12.846661Z","shell.execute_reply.started":"2025-01-24T16:26:12.567516Z","shell.execute_reply":"2025-01-24T16:26:12.845887Z"}},"outputs":[{"name":"stdout","text":"Class Distribution:\nlabel\nPositive    1800000\nNegative    1800000\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"!pip install spacy nltk\n!python -m spacy download en_core_web_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T14:38:03.949137Z","iopub.execute_input":"2025-01-15T14:38:03.949451Z","iopub.status.idle":"2025-01-15T14:38:23.735557Z","shell.execute_reply.started":"2025-01-15T14:38:03.949427Z","shell.execute_reply":"2025-01-15T14:38:23.73451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet')\nnltk.download('omw-1.4')  # Optional, for multilingual WordNet support","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T14:38:24.319592Z","iopub.execute_input":"2025-01-15T14:38:24.319909Z","iopub.status.idle":"2025-01-15T14:38:24.621707Z","shell.execute_reply.started":"2025-01-15T14:38:24.319884Z","shell.execute_reply":"2025-01-15T14:38:24.620735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import spacy\n\ntry:\n    spacy.require_gpu()\n    print(\"spaCy GPU enabled.\")\nexcept:\n    print(\"GPU not available. Using CPU.\")\n    \nnlp = spacy.load(\"en_core_web_sm\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T14:38:26.846609Z","iopub.execute_input":"2025-01-15T14:38:26.84698Z","iopub.status.idle":"2025-01-15T14:38:31.133857Z","shell.execute_reply.started":"2025-01-15T14:38:26.846949Z","shell.execute_reply":"2025-01-15T14:38:31.133141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T14:38:44.879248Z","iopub.execute_input":"2025-01-15T14:38:44.87979Z","iopub.status.idle":"2025-01-15T14:42:31.546794Z","shell.execute_reply.started":"2025-01-15T14:38:44.879764Z","shell.execute_reply":"2025-01-15T14:42:31.545677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install gputil\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T14:46:40.81664Z","iopub.execute_input":"2025-01-15T14:46:40.81703Z","iopub.status.idle":"2025-01-15T14:46:44.146965Z","shell.execute_reply.started":"2025-01-15T14:46:40.817004Z","shell.execute_reply":"2025-01-15T14:46:44.146075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T14:46:54.967096Z","iopub.execute_input":"2025-01-15T14:46:54.967562Z","iopub.status.idle":"2025-01-15T14:46:55.388025Z","shell.execute_reply.started":"2025-01-15T14:46:54.967523Z","shell.execute_reply":"2025-01-15T14:46:55.386956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nimport os\nimport logging\nfrom tqdm import tqdm\nimport zipfile\nimport fireducks.pandas as pd\nfrom spacy import load\nfrom spacy.cli import download\nimport torch\nimport tensorflow as tf\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\nlogger = logging.getLogger()\n\n# Function for batch preprocessing with lemmatization\ndef preprocess_in_batches(texts, nlp):\n    docs = nlp.pipe(texts, batch_size=2000)  # Batch processing for efficiency\n    return [' '.join([token.lemma_ for token in doc if token.is_alpha and not token.is_stop]) for doc in docs]\n\n# Chunked preprocessing function\ndef process_in_chunks(data, nlp, chunk_size=50000, save_path=\"/kaggle/working/processed_chunk\"):\n    total_rows = len(data)\n    start_time = time.time()\n\n    # Ensure the save path exists\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)  # Create the directory if it doesn't exist\n\n    # Process data in chunks\n    for start in range(0, total_rows, chunk_size):\n        chunk_start_time = time.time()\n        end = min(start + chunk_size, total_rows)\n        logger.info(f\"Processing rows {start} to {end}...\")\n\n        # Extract the current chunk\n        chunk = data.iloc[start:end].copy()  # Use `.iloc` for slicing\n\n        # Batch process the reviews\n        chunk['cleaned_review'] = preprocess_in_batches(chunk['review'], nlp)\n\n        # Save the processed chunk\n        chunk_save_path = f\"{save_path}/processed_chunk_{start}_{end}.csv\"\n        chunk.to_csv(chunk_save_path, index=False)\n        logger.info(f\"Saved processed chunk to {chunk_save_path}.\")\n        logger.info(f\"Chunk {start} to {end} processed in {time.time() - chunk_start_time:.2f} seconds.\")\n\n    logger.info(f\"Total processing time: {time.time() - start_time:.2f} seconds.\")\n\n# Option to zip all processed chunks after completion\ndef zip_processed_chunks(save_path=\"/kaggle/working/processed_chunk\"):\n    zip_file = \"/kaggle/working/processed_chunks.zip\"\n    with zipfile.ZipFile(zip_file, 'w') as zipf:\n        for file in os.listdir(save_path):\n            if file.startswith(\"processed_chunk_\"):\n                zipf.write(os.path.join(save_path, file), arcname=file)\n    logger.info(f\"Processed chunks zipped into {zip_file}\")\n    return zip_file\n\n# Main script\nif __name__ == \"__main__\":\n    try:\n        # Enable GPU usage for spaCy if available\n        import spacy\n        spacy.prefer_gpu()\n        logger.info(\"spaCy is configured to use GPU if available.\")\n\n        # Check if PyTorch and TensorFlow can utilize GPU\n        if torch.cuda.is_available():\n            device = torch.device(\"cuda\")\n            logger.info(f\"PyTorch GPU detected: {torch.cuda.get_device_name(device)}\")\n        else:\n            device = torch.device(\"cpu\")\n            logger.info(\"PyTorch is using CPU.\")\n\n        if len(tf.config.list_physical_devices('GPU')) > 0:\n            logger.info(f\"TensorFlow GPU detected: {tf.config.list_physical_devices('GPU')}\")\n        else:\n            logger.info(\"TensorFlow is using CPU.\")\n\n        # Download and load the spaCy model\n        try:\n            nlp = load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n        except OSError:\n            logger.info(\"Downloading spaCy model...\")\n            download(\"en_core_web_sm\")\n            nlp = load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n\n        # Paths\n        file_path = '/kaggle/input/amazonreviews/train.ft.txt.bz2'\n        save_path = \"/kaggle/working/processed_chunk\"\n\n        # Load the dataset\n        logger.info(\"Loading dataset...\")\n        data = pd.read_csv(file_path, sep='\\t', header=None, names=['text'], compression='bz2')\n\n        # Extract labels and reviews\n        logger.info(\"Extracting labels and reviews...\")\n        data['label'] = data['text'].apply(lambda x: int(x.split()[0].replace('__label__', '')))\n        data['review'] = data['text'].apply(lambda x: ' '.join(x.split()[1:]))\n        data = data[['review', 'label']]  # Retain only relevant columns\n\n        # Start preprocessing\n        logger.info(\"Starting preprocessing...\")\n        process_in_chunks(data, nlp, chunk_size=50000, save_path=save_path)\n\n        # Optionally, zip processed chunks after processing is done\n        logger.info(\"Zipping processed chunks...\")\n        zip_file = zip_processed_chunks(save_path=save_path)\n        logger.info(f\"Zipped file location: {zip_file}\")\n\n    except Exception as e:\n        logger.error(f\"An error occurred: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T14:47:04.570061Z","iopub.execute_input":"2025-01-15T14:47:04.570399Z","execution_failed":"2025-01-15T17:42:04.254Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ***After Preprocessing***","metadata":{}},{"cell_type":"code","source":"import fireducks.pandas as pd\nimport os\n\n# Path to the extracted chunk files (from your Kaggle dataset structure)\nextracted_chunks_path = \"/kaggle/input/processed-chunks-1\"  # Adjust if the path differs\n\n# Combine all chunk files\nall_chunks = []\nfor file_name in sorted(os.listdir(extracted_chunks_path)):  # Ensure files are combined in order\n    if file_name.startswith(\"processed_chunk_\") and file_name.endswith(\".csv\"):\n        file_path = os.path.join(extracted_chunks_path, file_name)\n        print(f\"Loading {file_name}...\")\n        chunk = pd.read_csv(file_path)\n        all_chunks.append(chunk)\n\n# Concatenate all chunks into a single DataFrame\ncombined_data = pd.concat(all_chunks, ignore_index=True)\n\n# Display combined data info\nprint(\"Combined data shape:\", combined_data.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:50:43.748946Z","iopub.execute_input":"2025-01-26T12:50:43.74938Z","iopub.status.idle":"2025-01-26T12:50:56.110167Z","shell.execute_reply.started":"2025-01-26T12:50:43.749348Z","shell.execute_reply":"2025-01-26T12:50:56.108988Z"}},"outputs":[{"name":"stdout","text":"Loading processed_chunk_0_50000.csv...\nLoading processed_chunk_1000000_1050000.csv...\nLoading processed_chunk_100000_150000.csv...\nLoading processed_chunk_1050000_1100000.csv...\nLoading processed_chunk_1100000_1150000.csv...\nLoading processed_chunk_1150000_1200000.csv...\nLoading processed_chunk_1200000_1250000.csv...\nLoading processed_chunk_1250000_1300000.csv...\nLoading processed_chunk_1300000_1350000.csv...\nLoading processed_chunk_1350000_1400000.csv...\nLoading processed_chunk_1400000_1450000.csv...\nLoading processed_chunk_1450000_1500000.csv...\nLoading processed_chunk_1500000_1550000.csv...\nLoading processed_chunk_150000_200000.csv...\nLoading processed_chunk_1550000_1600000.csv...\nLoading processed_chunk_1600000_1650000.csv...\nLoading processed_chunk_1650000_1700000.csv...\nLoading processed_chunk_1700000_1750000.csv...\nLoading processed_chunk_1750000_1800000.csv...\nLoading processed_chunk_1800000_1850000.csv...\nLoading processed_chunk_1850000_1900000.csv...\nLoading processed_chunk_1900000_1950000.csv...\nLoading processed_chunk_1950000_2000000.csv...\nLoading processed_chunk_2000000_2050000.csv...\nLoading processed_chunk_200000_250000.csv...\nLoading processed_chunk_2050000_2100000.csv...\nLoading processed_chunk_2100000_2150000.csv...\nLoading processed_chunk_2150000_2200000.csv...\nLoading processed_chunk_2200000_2250000.csv...\nLoading processed_chunk_2250000_2300000.csv...\nLoading processed_chunk_2300000_2350000.csv...\nLoading processed_chunk_2350000_2400000.csv...\nLoading processed_chunk_2400000_2450000.csv...\nLoading processed_chunk_2450000_2500000.csv...\nLoading processed_chunk_2500000_2550000.csv...\nLoading processed_chunk_250000_300000.csv...\nLoading processed_chunk_2550000_2600000.csv...\nLoading processed_chunk_2600000_2650000.csv...\nLoading processed_chunk_2650000_2700000.csv...\nLoading processed_chunk_2700000_2750000.csv...\nLoading processed_chunk_2750000_2800000.csv...\nLoading processed_chunk_2800000_2850000.csv...\nLoading processed_chunk_2850000_2900000.csv...\nLoading processed_chunk_2900000_2950000.csv...\nLoading processed_chunk_2950000_3000000.csv...\nLoading processed_chunk_3000000_3050000.csv...\nLoading processed_chunk_300000_350000.csv...\nLoading processed_chunk_3050000_3100000.csv...\nLoading processed_chunk_3100000_3150000.csv...\nLoading processed_chunk_3150000_3200000.csv...\nLoading processed_chunk_3200000_3250000.csv...\nLoading processed_chunk_3250000_3300000.csv...\nLoading processed_chunk_3300000_3350000.csv...\nLoading processed_chunk_3350000_3400000.csv...\nLoading processed_chunk_3400000_3450000.csv...\nLoading processed_chunk_3450000_3500000.csv...\nLoading processed_chunk_3500000_3550000.csv...\nLoading processed_chunk_350000_400000.csv...\nLoading processed_chunk_3550000_3600000.csv...\nLoading processed_chunk_400000_450000.csv...\nLoading processed_chunk_450000_500000.csv...\nLoading processed_chunk_500000_550000.csv...\nLoading processed_chunk_50000_100000.csv...\nLoading processed_chunk_550000_600000.csv...\nLoading processed_chunk_600000_650000.csv...\nLoading processed_chunk_650000_700000.csv...\nLoading processed_chunk_700000_750000.csv...\nLoading processed_chunk_750000_800000.csv...\nLoading processed_chunk_800000_850000.csv...\nLoading processed_chunk_850000_900000.csv...\nLoading processed_chunk_900000_950000.csv...\nLoading processed_chunk_950000_1000000.csv...\nCombined data shape: (3600000, 3)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Save the combined dataset as a CSV for future use\ncombined_data_path = \"/kaggle/working/combined_processed_data.csv\"\ncombined_data.to_csv(combined_data_path, index=False)\nprint(f\"Combined data saved at: {combined_data_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:51:03.689672Z","iopub.execute_input":"2025-01-26T12:51:03.690042Z","iopub.status.idle":"2025-01-26T12:51:09.013263Z","shell.execute_reply.started":"2025-01-26T12:51:03.690007Z","shell.execute_reply":"2025-01-26T12:51:09.011752Z"}},"outputs":[{"name":"stdout","text":"Combined data saved at: /kaggle/working/combined_processed_data.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load the saved combined dataset\ncombined_data = pd.read_csv(\"/kaggle/working/combined_processed_data.csv\")\n\n# Check the dataset structure\nprint(combined_data.info())\nprint(combined_data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:51:12.172127Z","iopub.execute_input":"2025-01-26T12:51:12.172474Z","iopub.status.idle":"2025-01-26T12:51:22.378544Z","shell.execute_reply.started":"2025-01-26T12:51:12.172446Z","shell.execute_reply":"2025-01-26T12:51:22.377449Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3600000 entries, 0 to 3599999\nData columns (total 3 columns):\n #   Column          Dtype \n---  ------          ----- \n 0   review          object\n 1   label           int64 \n 2   cleaned_review  object\ndtypes: int64(1), object(2)\nmemory usage: 82.4+ MB\nNone\n                                              review  label  \\\n0  Stuning even for the non-gamer: This sound tra...      2   \n1  The best soundtrack ever to anything.: I'm rea...      2   \n2  Amazing!: This soundtrack is my favorite music...      2   \n3  Excellent Soundtrack: I truly like this soundt...      2   \n4  Remember, Pull Your Jaw Off The Floor After He...      2   \n\n                                      cleaned_review  \n0  stun non gamer sound track beautiful paint sen...  \n1  good soundtrack read lot review say good game ...  \n2  amazing soundtrack favorite music time hand in...  \n3  excellent soundtrack truly like soundtrack enj...  \n4  remember pull Jaw Floor hear play game know di...  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Check label distribution\nprint(combined_data['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:51:36.800144Z","iopub.execute_input":"2025-01-26T12:51:36.800492Z","iopub.status.idle":"2025-01-26T12:51:36.88056Z","shell.execute_reply.started":"2025-01-26T12:51:36.800466Z","shell.execute_reply":"2025-01-26T12:51:36.879653Z"}},"outputs":[{"name":"stdout","text":"label\n2    1800000\n1    1800000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into train and test sets\nX = combined_data['cleaned_review']  # Features (cleaned reviews)\ny = combined_data['label']           # Labels (1 for neutral, 2 for positive)\n\n# Perform train-test split (80% training, 20% testing)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Training samples: {X_train.shape[0]}\")\nprint(f\"Testing samples: {X_test.shape[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:51:39.952986Z","iopub.execute_input":"2025-01-26T12:51:39.953351Z","iopub.status.idle":"2025-01-26T12:51:44.439871Z","shell.execute_reply.started":"2025-01-26T12:51:39.953317Z","shell.execute_reply":"2025-01-26T12:51:44.438751Z"}},"outputs":[{"name":"stdout","text":"Training samples: 2880000\nTesting samples: 720000\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Hashing Vectorizer or Feature Engineering ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import HashingVectorizer\nfrom scipy.sparse import vstack\nfrom sklearn.model_selection import train_test_split\n\n# Ensure that 'combined_data['label']' contains 0 for negative, 1 for neutral, and 2 for positive\nX = combined_data['cleaned_review']  # Features (cleaned reviews)\ny = combined_data['label']           # Labels (0 for negative, 1 for neutral, 2 for positive)\n\n# Perform train-test split (90% training, 10% testing) with a reduced test size\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n\nprint(f\"Training samples: {X_train.shape[0]}\")\nprint(f\"Testing samples: {X_test.shape[0]}\")\n\n# Use HashingVectorizer for incremental vectorization\nhash_vectorizer = HashingVectorizer(n_features=5000, alternate_sign=False, ngram_range=(1, 2))\n\n# Batch processing function for HashingVectorizer\ndef batch_hash_transform(vectorizer, data, batch_size=100000):\n    \"\"\"Batch process large datasets for HashingVectorizer transformation.\"\"\"\n    batches = []\n    total = len(data)\n    for i in range(0, total, batch_size):\n        print(f\"Processing batch {i // batch_size + 1} / {total // batch_size + 1}\")\n        batch = data[i: i + batch_size].values.astype('U')  # Convert to Unicode\n        batches.append(vectorizer.transform(batch))\n    return vstack(batches)\n\n# Transform training data in batches\nprint(\"Starting HashingVectorizer transformation on training data...\")\nX_train_tfidf = batch_hash_transform(hash_vectorizer, X_train, batch_size=50000)\n\n# Transform testing data in batches\nprint(\"Starting HashingVectorizer transformation on testing data...\")\nX_test_tfidf = batch_hash_transform(hash_vectorizer, X_test, batch_size=50000)\n\nprint(\"HashingVectorizer transformation complete.\")\nprint(f\"Training Hashing shape: {X_train_tfidf.shape}\")\nprint(f\"Testing Hashing shape: {X_test_tfidf.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:51:47.791352Z","iopub.execute_input":"2025-01-26T12:51:47.791708Z","iopub.status.idle":"2025-01-26T12:54:26.092208Z","shell.execute_reply.started":"2025-01-26T12:51:47.791676Z","shell.execute_reply":"2025-01-26T12:54:26.091192Z"}},"outputs":[{"name":"stdout","text":"Training samples: 3240000\nTesting samples: 360000\nStarting HashingVectorizer transformation on training data...\nProcessing batch 1 / 65\nProcessing batch 2 / 65\nProcessing batch 3 / 65\nProcessing batch 4 / 65\nProcessing batch 5 / 65\nProcessing batch 6 / 65\nProcessing batch 7 / 65\nProcessing batch 8 / 65\nProcessing batch 9 / 65\nProcessing batch 10 / 65\nProcessing batch 11 / 65\nProcessing batch 12 / 65\nProcessing batch 13 / 65\nProcessing batch 14 / 65\nProcessing batch 15 / 65\nProcessing batch 16 / 65\nProcessing batch 17 / 65\nProcessing batch 18 / 65\nProcessing batch 19 / 65\nProcessing batch 20 / 65\nProcessing batch 21 / 65\nProcessing batch 22 / 65\nProcessing batch 23 / 65\nProcessing batch 24 / 65\nProcessing batch 25 / 65\nProcessing batch 26 / 65\nProcessing batch 27 / 65\nProcessing batch 28 / 65\nProcessing batch 29 / 65\nProcessing batch 30 / 65\nProcessing batch 31 / 65\nProcessing batch 32 / 65\nProcessing batch 33 / 65\nProcessing batch 34 / 65\nProcessing batch 35 / 65\nProcessing batch 36 / 65\nProcessing batch 37 / 65\nProcessing batch 38 / 65\nProcessing batch 39 / 65\nProcessing batch 40 / 65\nProcessing batch 41 / 65\nProcessing batch 42 / 65\nProcessing batch 43 / 65\nProcessing batch 44 / 65\nProcessing batch 45 / 65\nProcessing batch 46 / 65\nProcessing batch 47 / 65\nProcessing batch 48 / 65\nProcessing batch 49 / 65\nProcessing batch 50 / 65\nProcessing batch 51 / 65\nProcessing batch 52 / 65\nProcessing batch 53 / 65\nProcessing batch 54 / 65\nProcessing batch 55 / 65\nProcessing batch 56 / 65\nProcessing batch 57 / 65\nProcessing batch 58 / 65\nProcessing batch 59 / 65\nProcessing batch 60 / 65\nProcessing batch 61 / 65\nProcessing batch 62 / 65\nProcessing batch 63 / 65\nProcessing batch 64 / 65\nProcessing batch 65 / 65\nStarting HashingVectorizer transformation on testing data...\nProcessing batch 1 / 8\nProcessing batch 2 / 8\nProcessing batch 3 / 8\nProcessing batch 4 / 8\nProcessing batch 5 / 8\nProcessing batch 6 / 8\nProcessing batch 7 / 8\nProcessing batch 8 / 8\nHashingVectorizer transformation complete.\nTraining Hashing shape: (3240000, 5000)\nTesting Hashing shape: (360000, 5000)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import joblib\n\n# Save the HashingVectorizer\njoblib.dump(hash_vectorizer, '/kaggle/working/hashing_vectorizer.pkl')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:55:14.803013Z","iopub.execute_input":"2025-01-26T12:55:14.803364Z","iopub.status.idle":"2025-01-26T12:55:14.810747Z","shell.execute_reply.started":"2025-01-26T12:55:14.803336Z","shell.execute_reply":"2025-01-26T12:55:14.809889Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/hashing_vectorizer.pkl']"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"print(combined_data['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:55:17.391157Z","iopub.execute_input":"2025-01-26T12:55:17.391501Z","iopub.status.idle":"2025-01-26T12:55:17.447071Z","shell.execute_reply.started":"2025-01-26T12:55:17.391468Z","shell.execute_reply":"2025-01-26T12:55:17.445884Z"}},"outputs":[{"name":"stdout","text":"label\n2    1800000\n1    1800000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":" # Model-1\n> XGBOOST","metadata":{}},{"cell_type":"code","source":"from xgboost import DMatrix, XGBClassifier, cv\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\n\n# Adjust target labels to be 0-based\ny_train_adjusted = y_train - 1\ny_test_adjusted = y_test - 1\n\n# Convert training data to DMatrix\ndtrain = DMatrix(X_train_tfidf, label=y_train_adjusted)\n\n# Define hyperparameter grid\nlearning_rates = [0.01, 0.05, 0.1]\nn_estimators_values = [100, 200, 500]\nmax_depth_values = [3, 5, 7]\nmin_child_weight_values = [1, 5, 10]\ngamma_values = [0, 0.1, 0.2]\n\n# Cross-validation setup\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Iterate over hyperparameters\nfor lr in learning_rates:\n    for n_est in n_estimators_values:\n        for max_depth in max_depth_values:\n            for min_child_weight in min_child_weight_values:\n                for gamma in gamma_values:\n                    print(f\"Training XGBoost classifier with learning_rate={lr}, n_estimators={n_est}, max_depth={max_depth}, min_child_weight={min_child_weight}, gamma={gamma}...\")\n\n                    # Set up the XGBoost model with regularization and early stopping\n                    xgb_classifier = XGBClassifier(\n                        learning_rate=lr,\n                        n_estimators=n_est,\n                        max_depth=max_depth,\n                        min_child_weight=min_child_weight,\n                        gamma=gamma,\n                        use_label_encoder=False,\n                        eval_metric='logloss',  # Set eval_metric here\n                        tree_method='hist',\n                        device='cuda',  # Specify GPU for training\n                    )\n\n                    # Cross-validation to monitor the model's generalization\n                    cv_results = cv(\n                        dtrain=dtrain, \n                        params=xgb_classifier.get_params(), \n                        num_boost_round=n_est, \n                        nfold=5, \n                        early_stopping_rounds=10,  # Early stopping if performance doesn't improve\n                        metrics='logloss', \n                        as_pandas=True,\n                        seed=42\n                    )\n\n                    # Best iteration (round) from cross-validation results\n                    best_iter = cv_results['test-logloss-mean'].idxmin()\n                    print(f\"Best round from CV: {best_iter}\")\n\n                    # Define a validation set for early stopping\n                    eval_set = [(X_train_tfidf, y_train_adjusted), (X_test_tfidf, y_test_adjusted)]\n\n                    # Train the model with the best number of rounds and provide the validation set\n                    xgb_classifier.fit(X_train_tfidf, y_train_adjusted, early_stopping_rounds=10, eval_set=eval_set)\n\n                    print(\"Predicting with XGBoost...\")\n                    y_pred_xgb = xgb_classifier.predict(X_test_tfidf)\n\n                    # Adjust predictions back to the original label scale for reporting\n                    y_pred_xgb_original = y_pred_xgb + 1\n\n                    # Performance reporting\n                    print(f\"XGBoost Classification Report for learning_rate={lr}, n_estimators={n_est}, max_depth={max_depth}, min_child_weight={min_child_weight}, gamma={gamma}:\")\n                    print(classification_report(y_test, y_pred_xgb_original))\n                    accuracy = accuracy_score(y_test, y_pred_xgb_original)\n                    print(f\"XGBoost Accuracy with learning_rate={lr}, n_estimators={n_est}, max_depth={max_depth}, min_child_weight={min_child_weight}, gamma={gamma}: {accuracy:.4f}\\n\")\n","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* # **LightGBM**","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score\nimport psutil\nimport numpy as np\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Adjust target labels to be 0-based\ny_train_adjusted = y_train - 1\ny_test_adjusted = y_test - 1\n\n# Convert labels to numpy arrays\ny_train_adjusted = np.array(y_train_adjusted)\ny_test_adjusted = np.array(y_test_adjusted)\n\n# Define hyperparameter grid for LightGBM (with smaller iterations)\nlearning_rates = [0.01, 0.05]\niterations_values = [50, 100]  # Reduced iterations\ndepth_values = [3, 5]\nnum_leaves_values = [15, 31]\n\n# Cross-validation setup (reduced folds to save memory)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # 3 folds\n\n# Iterate over hyperparameters\nfor lr in learning_rates:\n    for iterations in iterations_values:\n        for depth in depth_values:\n            for num_leaves in num_leaves_values:\n                print(f\"Training LightGBM classifier with learning_rate={lr}, iterations={iterations}, depth={depth}, num_leaves={num_leaves}...\")\n\n                # Set up the LightGBM model with the specified hyperparameters\n                lgbm_classifier = lgb.LGBMClassifier(\n                    learning_rate=lr,\n                    n_estimators=iterations,\n                    max_depth=depth,\n                    num_leaves=num_leaves,\n                    verbose=-1,\n                    n_jobs=-1  # Use all available CPU cores\n                )\n\n                # Cross-validation setup\n                lgbm_classifier.fit(X_train_tfidf[:10000], y_train_adjusted[:10000])  # Use a smaller subset\n                y_pred_lgbm = lgbm_classifier.predict(X_test_tfidf)\n\n                # Adjust predictions back to the original label scale for reporting\n                y_pred_lgbm_original = y_pred_lgbm + 1\n\n                # Performance reporting\n                print(f\"LightGBM Classification Report for learning_rate={lr}, iterations={iterations}, depth={depth}, num_leaves={num_leaves}:\")\n                print(classification_report(y_test, y_pred_lgbm_original))\n                accuracy = accuracy_score(y_test, y_pred_lgbm_original)\n                print(f\"LightGBM Accuracy: {accuracy:.4f}\\n\")\n\n                # Check memory usage after each iteration\n                check_memory()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:55:30.329696Z","iopub.execute_input":"2025-01-26T12:55:30.330036Z","iopub.status.idle":"2025-01-26T12:56:05.939573Z","shell.execute_reply.started":"2025-01-26T12:55:30.33001Z","shell.execute_reply":"2025-01-26T12:56:05.938564Z"}},"outputs":[{"name":"stdout","text":"Training LightGBM classifier with learning_rate=0.01, iterations=50, depth=3, num_leaves=15...\nLightGBM Classification Report for learning_rate=0.01, iterations=50, depth=3, num_leaves=15:\n              precision    recall  f1-score   support\n\n           1       0.68      0.73      0.70    180000\n           2       0.71      0.65      0.68    180000\n\n    accuracy                           0.69    360000\n   macro avg       0.69      0.69      0.69    360000\nweighted avg       0.69      0.69      0.69    360000\n\nLightGBM Accuracy: 0.6916\n\nMemory usage: 46.9%\nTraining LightGBM classifier with learning_rate=0.01, iterations=50, depth=3, num_leaves=31...\nLightGBM Classification Report for learning_rate=0.01, iterations=50, depth=3, num_leaves=31:\n              precision    recall  f1-score   support\n\n           1       0.68      0.73      0.70    180000\n           2       0.71      0.65      0.68    180000\n\n    accuracy                           0.69    360000\n   macro avg       0.69      0.69      0.69    360000\nweighted avg       0.69      0.69      0.69    360000\n\nLightGBM Accuracy: 0.6916\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.01, iterations=50, depth=5, num_leaves=15...\nLightGBM Classification Report for learning_rate=0.01, iterations=50, depth=5, num_leaves=15:\n              precision    recall  f1-score   support\n\n           1       0.68      0.75      0.71    180000\n           2       0.72      0.65      0.68    180000\n\n    accuracy                           0.70    360000\n   macro avg       0.70      0.70      0.70    360000\nweighted avg       0.70      0.70      0.70    360000\n\nLightGBM Accuracy: 0.6977\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.01, iterations=50, depth=5, num_leaves=31...\nLightGBM Classification Report for learning_rate=0.01, iterations=50, depth=5, num_leaves=31:\n              precision    recall  f1-score   support\n\n           1       0.68      0.74      0.71    180000\n           2       0.72      0.65      0.68    180000\n\n    accuracy                           0.70    360000\n   macro avg       0.70      0.70      0.70    360000\nweighted avg       0.70      0.70      0.70    360000\n\nLightGBM Accuracy: 0.6962\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.01, iterations=100, depth=3, num_leaves=15...\nLightGBM Classification Report for learning_rate=0.01, iterations=100, depth=3, num_leaves=15:\n              precision    recall  f1-score   support\n\n           1       0.68      0.75      0.71    180000\n           2       0.72      0.64      0.68    180000\n\n    accuracy                           0.70    360000\n   macro avg       0.70      0.70      0.70    360000\nweighted avg       0.70      0.70      0.70    360000\n\nLightGBM Accuracy: 0.6967\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.01, iterations=100, depth=3, num_leaves=31...\nLightGBM Classification Report for learning_rate=0.01, iterations=100, depth=3, num_leaves=31:\n              precision    recall  f1-score   support\n\n           1       0.68      0.75      0.71    180000\n           2       0.72      0.64      0.68    180000\n\n    accuracy                           0.70    360000\n   macro avg       0.70      0.70      0.70    360000\nweighted avg       0.70      0.70      0.70    360000\n\nLightGBM Accuracy: 0.6967\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.01, iterations=100, depth=5, num_leaves=15...\nLightGBM Classification Report for learning_rate=0.01, iterations=100, depth=5, num_leaves=15:\n              precision    recall  f1-score   support\n\n           1       0.68      0.76      0.72    180000\n           2       0.73      0.65      0.69    180000\n\n    accuracy                           0.70    360000\n   macro avg       0.71      0.70      0.70    360000\nweighted avg       0.71      0.70      0.70    360000\n\nLightGBM Accuracy: 0.7033\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.01, iterations=100, depth=5, num_leaves=31...\nLightGBM Classification Report for learning_rate=0.01, iterations=100, depth=5, num_leaves=31:\n              precision    recall  f1-score   support\n\n           1       0.68      0.76      0.72    180000\n           2       0.73      0.65      0.69    180000\n\n    accuracy                           0.70    360000\n   macro avg       0.70      0.70      0.70    360000\nweighted avg       0.70      0.70      0.70    360000\n\nLightGBM Accuracy: 0.7022\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.05, iterations=50, depth=3, num_leaves=15...\nLightGBM Classification Report for learning_rate=0.05, iterations=50, depth=3, num_leaves=15:\n              precision    recall  f1-score   support\n\n           1       0.70      0.77      0.73    180000\n           2       0.74      0.67      0.71    180000\n\n    accuracy                           0.72    360000\n   macro avg       0.72      0.72      0.72    360000\nweighted avg       0.72      0.72      0.72    360000\n\nLightGBM Accuracy: 0.7197\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.05, iterations=50, depth=3, num_leaves=31...\nLightGBM Classification Report for learning_rate=0.05, iterations=50, depth=3, num_leaves=31:\n              precision    recall  f1-score   support\n\n           1       0.70      0.77      0.73    180000\n           2       0.74      0.67      0.71    180000\n\n    accuracy                           0.72    360000\n   macro avg       0.72      0.72      0.72    360000\nweighted avg       0.72      0.72      0.72    360000\n\nLightGBM Accuracy: 0.7197\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.05, iterations=50, depth=5, num_leaves=15...\nLightGBM Classification Report for learning_rate=0.05, iterations=50, depth=5, num_leaves=15:\n              precision    recall  f1-score   support\n\n           1       0.73      0.77      0.75    180000\n           2       0.75      0.71      0.73    180000\n\n    accuracy                           0.74    360000\n   macro avg       0.74      0.74      0.74    360000\nweighted avg       0.74      0.74      0.74    360000\n\nLightGBM Accuracy: 0.7403\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.05, iterations=50, depth=5, num_leaves=31...\nLightGBM Classification Report for learning_rate=0.05, iterations=50, depth=5, num_leaves=31:\n              precision    recall  f1-score   support\n\n           1       0.73      0.77      0.75    180000\n           2       0.75      0.72      0.73    180000\n\n    accuracy                           0.74    360000\n   macro avg       0.74      0.74      0.74    360000\nweighted avg       0.74      0.74      0.74    360000\n\nLightGBM Accuracy: 0.7403\n\nMemory usage: 47.1%\nTraining LightGBM classifier with learning_rate=0.05, iterations=100, depth=3, num_leaves=15...\nLightGBM Classification Report for learning_rate=0.05, iterations=100, depth=3, num_leaves=15:\n              precision    recall  f1-score   support\n\n           1       0.73      0.77      0.75    180000\n           2       0.76      0.72      0.74    180000\n\n    accuracy                           0.74    360000\n   macro avg       0.75      0.74      0.74    360000\nweighted avg       0.75      0.74      0.74    360000\n\nLightGBM Accuracy: 0.7449\n\nMemory usage: 47.2%\nTraining LightGBM classifier with learning_rate=0.05, iterations=100, depth=3, num_leaves=31...\nLightGBM Classification Report for learning_rate=0.05, iterations=100, depth=3, num_leaves=31:\n              precision    recall  f1-score   support\n\n           1       0.73      0.77      0.75    180000\n           2       0.76      0.72      0.74    180000\n\n    accuracy                           0.74    360000\n   macro avg       0.75      0.74      0.74    360000\nweighted avg       0.75      0.74      0.74    360000\n\nLightGBM Accuracy: 0.7449\n\nMemory usage: 47.2%\nTraining LightGBM classifier with learning_rate=0.05, iterations=100, depth=5, num_leaves=15...\nLightGBM Classification Report for learning_rate=0.05, iterations=100, depth=5, num_leaves=15:\n              precision    recall  f1-score   support\n\n           1       0.75      0.78      0.76    180000\n           2       0.77      0.74      0.75    180000\n\n    accuracy                           0.76    360000\n   macro avg       0.76      0.76      0.76    360000\nweighted avg       0.76      0.76      0.76    360000\n\nLightGBM Accuracy: 0.7593\n\nMemory usage: 47.2%\nTraining LightGBM classifier with learning_rate=0.05, iterations=100, depth=5, num_leaves=31...\nLightGBM Classification Report for learning_rate=0.05, iterations=100, depth=5, num_leaves=31:\n              precision    recall  f1-score   support\n\n           1       0.75      0.78      0.76    180000\n           2       0.77      0.74      0.75    180000\n\n    accuracy                           0.76    360000\n   macro avg       0.76      0.76      0.76    360000\nweighted avg       0.76      0.76      0.76    360000\n\nLightGBM Accuracy: 0.7593\n\nMemory usage: 47.2%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"* # **CatBoost**","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier, cv, Pool\nfrom sklearn.metrics import classification_report, accuracy_score\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nimport psutil\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Adjust target labels to be 0-based\ny_train_adjusted = y_train - 1\ny_test_adjusted = y_test - 1\n\n# Convert labels to numpy arrays\ny_train_adjusted = np.array(y_train_adjusted)\ny_test_adjusted = np.array(y_test_adjusted)\n\n# Define hyperparameter grid for CatBoost (with smaller iterations)\nlearning_rates = [0.01, 0.05]\niterations_values = [50, 100]  # Reduced iterations\ndepth_values = [3, 5]\nl2_leaf_reg_values = [1, 3]\nborder_count_values = [32, 50]\n\n# Cross-validation setup (reduced folds to save memory)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # 3 folds\n\n# Iterate over hyperparameters\nfor lr in learning_rates:\n    for iterations in iterations_values:\n        for depth in depth_values:\n            for l2_leaf_reg in l2_leaf_reg_values:\n                for border_count in border_count_values:\n                    print(f\"Training CatBoost classifier with learning_rate={lr}, iterations={iterations}, depth={depth}, l2_leaf_reg={l2_leaf_reg}, border_count={border_count}...\")\n\n                    # Set up the CatBoost model with the specified hyperparameters\n                    catboost_classifier = CatBoostClassifier(\n                        learning_rate=lr,\n                        iterations=iterations,\n                        depth=depth,\n                        l2_leaf_reg=l2_leaf_reg,\n                        border_count=border_count,\n                        verbose=0,  # To suppress verbose output\n                        thread_count=-1  # Use all available CPU cores\n                    )\n\n                    # Prepare data as Pool objects for CatBoost\n                    train_pool = Pool(X_train_tfidf[:10000], label=y_train_adjusted[:10000])  # Use a smaller subset\n                    test_pool = Pool(X_test_tfidf, label=y_test_adjusted)\n\n                    # Cross-validation to monitor the model's generalization\n                    params = catboost_classifier.get_params()\n                    params['eval_metric'] = 'Accuracy'  # Specify metric for evaluation\n                    params['loss_function'] = 'Logloss'  # Specify the loss function\n\n                    cv_results = cv(\n                        pool=train_pool,  # Provide the training data in Pool format\n                        params=params,  # Pass model parameters\n                        num_boost_round=iterations, \n                        nfold=3,  # Reduced folds to save memory\n                        early_stopping_rounds=10,  # Early stopping if performance doesn't improve\n                        as_pandas=True,\n                        seed=42\n                    )\n\n                    # Best iteration (round) from cross-validation results\n                    best_iter = cv_results['test-Accuracy-mean'].idxmax()  # Best round based on accuracy\n                    print(f\"Best round from CV: {best_iter}\")\n\n                    # Train the model with the best number of rounds\n                    catboost_classifier.fit(X_train_tfidf, y_train_adjusted, verbose=0)\n\n                    print(\"Predicting with CatBoost...\")\n                    y_pred_catboost = catboost_classifier.predict(X_test_tfidf)\n\n                    # Adjust predictions back to the original label scale for reporting\n                    y_pred_catboost_original = y_pred_catboost + 1\n\n                    # Performance reporting\n                    print(f\"CatBoost Classification Report for learning_rate={lr}, iterations={iterations}, depth={depth}, l2_leaf_reg={l2_leaf_reg}, border_count={border_count}:\")\n                    print(classification_report(y_test, y_pred_catboost_original))\n                    accuracy = accuracy_score(y_test, y_pred_catboost_original)\n                    print(f\"CatBoost Accuracy with learning_rate={lr}, iterations={iterations}, depth={depth}, l2_leaf_reg={l2_leaf_reg}, border_count={border_count}: {accuracy:.4f}\\n\")\n\n                    # Check memory usage after each iteration\n                    check_memory()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:44:23.710874Z","iopub.execute_input":"2025-01-26T12:44:23.711251Z","iopub.status.idle":"2025-01-26T12:44:26.306816Z","shell.execute_reply.started":"2025-01-26T12:44:23.71122Z","shell.execute_reply":"2025-01-26T12:44:26.305619Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d9cafd5273cb>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Adjust target labels to be 0-based\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_train_adjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my_test_adjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"],"ename":"NameError","evalue":"name 'y_train' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"* # **Random Forest**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score\nimport psutil\nimport numpy as np\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Adjust target labels to be 0-based\ny_train_adjusted = y_train - 1\ny_test_adjusted = y_test - 1\n\n# Convert labels to numpy arrays\ny_train_adjusted = np.array(y_train_adjusted)\ny_test_adjusted = np.array(y_test_adjusted)\n\n# Define hyperparameter grid for RandomForest\nn_estimators_values = [50, 100]\ndepth_values = [3, 5]\nmin_samples_split_values = [2, 5]\n\n# Cross-validation setup (reduced folds to save memory)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # 3 folds\n\n# Iterate over hyperparameters\nfor n_estimators in n_estimators_values:\n    for depth in depth_values:\n        for min_samples_split in min_samples_split_values:\n            print(f\"Training Random Forest classifier with n_estimators={n_estimators}, depth={depth}, min_samples_split={min_samples_split}...\")\n\n            # Set up the Random Forest model with the specified hyperparameters\n            rf_classifier = RandomForestClassifier(\n                n_estimators=n_estimators,\n                max_depth=depth,\n                min_samples_split=min_samples_split,\n                n_jobs=-1,  # Use all available CPU cores\n                random_state=42\n            )\n\n            # Train the model\n            rf_classifier.fit(X_train_tfidf[:10000], y_train_adjusted[:10000])  # Use a smaller subset\n            y_pred_rf = rf_classifier.predict(X_test_tfidf)\n\n            # Adjust predictions back to the original label scale for reporting\n            y_pred_rf_original = y_pred_rf + 1\n\n            # Performance reporting\n            print(f\"Random Forest Classification Report for n_estimators={n_estimators}, depth={depth}, min_samples_split={min_samples_split}:\")\n            print(classification_report(y_test, y_pred_rf_original))\n            accuracy = accuracy_score(y_test, y_pred_rf_original)\n            print(f\"Random Forest Accuracy: {accuracy:.4f}\\n\")\n\n            # Check memory usage after each iteration\n            check_memory()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:59:37.108859Z","iopub.execute_input":"2025-01-26T12:59:37.109583Z","iopub.status.idle":"2025-01-26T12:59:56.956725Z","shell.execute_reply.started":"2025-01-26T12:59:37.109552Z","shell.execute_reply":"2025-01-26T12:59:56.955754Z"}},"outputs":[{"name":"stdout","text":"Training Random Forest classifier with n_estimators=50, depth=3, min_samples_split=2...\nRandom Forest Classification Report for n_estimators=50, depth=3, min_samples_split=2:\n              precision    recall  f1-score   support\n\n           1       0.76      0.65      0.70    180000\n           2       0.69      0.79      0.74    180000\n\n    accuracy                           0.72    360000\n   macro avg       0.73      0.72      0.72    360000\nweighted avg       0.73      0.72      0.72    360000\n\nRandom Forest Accuracy: 0.7212\n\nMemory usage: 47.4%\nTraining Random Forest classifier with n_estimators=50, depth=3, min_samples_split=5...\nRandom Forest Classification Report for n_estimators=50, depth=3, min_samples_split=5:\n              precision    recall  f1-score   support\n\n           1       0.76      0.65      0.70    180000\n           2       0.69      0.79      0.74    180000\n\n    accuracy                           0.72    360000\n   macro avg       0.73      0.72      0.72    360000\nweighted avg       0.73      0.72      0.72    360000\n\nRandom Forest Accuracy: 0.7212\n\nMemory usage: 47.5%\nTraining Random Forest classifier with n_estimators=50, depth=5, min_samples_split=2...\nRandom Forest Classification Report for n_estimators=50, depth=5, min_samples_split=2:\n              precision    recall  f1-score   support\n\n           1       0.77      0.70      0.73    180000\n           2       0.73      0.79      0.76    180000\n\n    accuracy                           0.74    360000\n   macro avg       0.75      0.74      0.74    360000\nweighted avg       0.75      0.74      0.74    360000\n\nRandom Forest Accuracy: 0.7449\n\nMemory usage: 47.5%\nTraining Random Forest classifier with n_estimators=50, depth=5, min_samples_split=5...\nRandom Forest Classification Report for n_estimators=50, depth=5, min_samples_split=5:\n              precision    recall  f1-score   support\n\n           1       0.77      0.70      0.73    180000\n           2       0.73      0.79      0.76    180000\n\n    accuracy                           0.75    360000\n   macro avg       0.75      0.75      0.74    360000\nweighted avg       0.75      0.75      0.74    360000\n\nRandom Forest Accuracy: 0.7450\n\nMemory usage: 47.5%\nTraining Random Forest classifier with n_estimators=100, depth=3, min_samples_split=2...\nRandom Forest Classification Report for n_estimators=100, depth=3, min_samples_split=2:\n              precision    recall  f1-score   support\n\n           1       0.78      0.69      0.73    180000\n           2       0.72      0.81      0.76    180000\n\n    accuracy                           0.75    360000\n   macro avg       0.75      0.75      0.75    360000\nweighted avg       0.75      0.75      0.75    360000\n\nRandom Forest Accuracy: 0.7469\n\nMemory usage: 47.5%\nTraining Random Forest classifier with n_estimators=100, depth=3, min_samples_split=5...\nRandom Forest Classification Report for n_estimators=100, depth=3, min_samples_split=5:\n              precision    recall  f1-score   support\n\n           1       0.78      0.69      0.73    180000\n           2       0.72      0.81      0.76    180000\n\n    accuracy                           0.75    360000\n   macro avg       0.75      0.75      0.75    360000\nweighted avg       0.75      0.75      0.75    360000\n\nRandom Forest Accuracy: 0.7469\n\nMemory usage: 47.5%\nTraining Random Forest classifier with n_estimators=100, depth=5, min_samples_split=2...\nRandom Forest Classification Report for n_estimators=100, depth=5, min_samples_split=2:\n              precision    recall  f1-score   support\n\n           1       0.78      0.71      0.75    180000\n           2       0.74      0.80      0.77    180000\n\n    accuracy                           0.76    360000\n   macro avg       0.76      0.76      0.76    360000\nweighted avg       0.76      0.76      0.76    360000\n\nRandom Forest Accuracy: 0.7562\n\nMemory usage: 47.5%\nTraining Random Forest classifier with n_estimators=100, depth=5, min_samples_split=5...\nRandom Forest Classification Report for n_estimators=100, depth=5, min_samples_split=5:\n              precision    recall  f1-score   support\n\n           1       0.78      0.71      0.75    180000\n           2       0.74      0.80      0.77    180000\n\n    accuracy                           0.76    360000\n   macro avg       0.76      0.76      0.76    360000\nweighted avg       0.76      0.76      0.76    360000\n\nRandom Forest Accuracy: 0.7562\n\nMemory usage: 47.5%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# **AdaBoost**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score\nimport psutil\nimport numpy as np\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Adjust target labels to be 0-based\ny_train_adjusted = y_train - 1\ny_test_adjusted = y_test - 1\n\n# Convert labels to numpy arrays\ny_train_adjusted = np.array(y_train_adjusted)\ny_test_adjusted = np.array(y_test_adjusted)\n\n# Define hyperparameter grid for AdaBoost\nn_estimators_values = [50, 100]\nlearning_rate_values = [0.01, 0.1]\n\n# Cross-validation setup (reduced folds to save memory)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # 3 folds\n\n# Iterate over hyperparameters\nfor n_estimators in n_estimators_values:\n    for learning_rate in learning_rate_values:\n        print(f\"Training AdaBoost classifier with n_estimators={n_estimators}, learning_rate={learning_rate}...\")\n\n        # Set up the AdaBoost model with the specified hyperparameters\n        adaboost_classifier = AdaBoostClassifier(\n            n_estimators=n_estimators,\n            learning_rate=learning_rate,\n            random_state=42\n        )\n\n        # Train the model\n        adaboost_classifier.fit(X_train_tfidf[:10000], y_train_adjusted[:10000])  # Use a smaller subset\n        y_pred_adaboost = adaboost_classifier.predict(X_test_tfidf)\n\n        # Adjust predictions back to the original label scale for reporting\n        y_pred_adaboost_original = y_pred_adaboost + 1\n\n        # Performance reporting\n        print(f\"AdaBoost Classification Report for n_estimators={n_estimators}, learning_rate={learning_rate}:\")\n        print(classification_report(y_test, y_pred_adaboost_original))\n        accuracy = accuracy_score(y_test, y_pred_adaboost_original)\n        print(f\"AdaBoost Accuracy: {accuracy:.4f}\\n\")\n\n        # Check memory usage after each iteration\n        check_memory()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T13:01:27.180666Z","iopub.execute_input":"2025-01-26T13:01:27.1811Z","iopub.status.idle":"2025-01-26T13:02:26.898213Z","shell.execute_reply.started":"2025-01-26T13:01:27.181065Z","shell.execute_reply":"2025-01-26T13:02:26.897134Z"}},"outputs":[{"name":"stdout","text":"Training AdaBoost classifier with n_estimators=50, learning_rate=0.01...\nAdaBoost Classification Report for n_estimators=50, learning_rate=0.01:\n              precision    recall  f1-score   support\n\n           1       0.57      0.89      0.70    180000\n           2       0.76      0.33      0.46    180000\n\n    accuracy                           0.61    360000\n   macro avg       0.67      0.61      0.58    360000\nweighted avg       0.67      0.61      0.58    360000\n\nAdaBoost Accuracy: 0.6134\n\nMemory usage: 47.2%\nTraining AdaBoost classifier with n_estimators=50, learning_rate=0.1...\nAdaBoost Classification Report for n_estimators=50, learning_rate=0.1:\n              precision    recall  f1-score   support\n\n           1       0.68      0.77      0.72    180000\n           2       0.74      0.64      0.69    180000\n\n    accuracy                           0.71    360000\n   macro avg       0.71      0.71      0.70    360000\nweighted avg       0.71      0.71      0.70    360000\n\nAdaBoost Accuracy: 0.7063\n\nMemory usage: 47.3%\nTraining AdaBoost classifier with n_estimators=100, learning_rate=0.01...\nAdaBoost Classification Report for n_estimators=100, learning_rate=0.01:\n              precision    recall  f1-score   support\n\n           1       0.60      0.86      0.71    180000\n           2       0.76      0.44      0.55    180000\n\n    accuracy                           0.65    360000\n   macro avg       0.68      0.65      0.63    360000\nweighted avg       0.68      0.65      0.63    360000\n\nAdaBoost Accuracy: 0.6485\n\nMemory usage: 47.3%\nTraining AdaBoost classifier with n_estimators=100, learning_rate=0.1...\nAdaBoost Classification Report for n_estimators=100, learning_rate=0.1:\n              precision    recall  f1-score   support\n\n           1       0.72      0.78      0.75    180000\n           2       0.76      0.70      0.73    180000\n\n    accuracy                           0.74    360000\n   macro avg       0.74      0.74      0.74    360000\nweighted avg       0.74      0.74      0.74    360000\n\nAdaBoost Accuracy: 0.7369\n\nMemory usage: 47.3%\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score\nimport psutil\nimport numpy as np\n\n# Function to check memory usage\ndef check_memory():\n    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n\n# Adjust target labels to be 0-based\ny_train_adjusted = y_train - 1\ny_test_adjusted = y_test - 1\n\n# Convert labels to numpy arrays\ny_train_adjusted = np.array(y_train_adjusted)\ny_test_adjusted = np.array(y_test_adjusted)\n\n# Define hyperparameter grid for MLP\nhidden_layer_sizes_values = [(100,), (128, 64)]\nactivation_values = ['relu', 'tanh']\nsolver_values = ['adam', 'sgd']\n\n# Cross-validation setup (reduced folds to save memory)\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # 3 folds\n\n# Iterate over hyperparameters\nfor hidden_layer_sizes in hidden_layer_sizes_values:\n    for activation in activation_values:\n        for solver in solver_values:\n            print(f\"Training MLPClassifier with hidden_layer_sizes={hidden_layer_sizes}, activation={activation}, solver={solver}...\")\n\n            # Set up the MLPClassifier model with the specified hyperparameters\n            mlp_classifier = MLPClassifier(\n                hidden_layer_sizes=hidden_layer_sizes,\n                activation=activation,\n                solver=solver,\n                max_iter=300,\n                random_state=42\n            )\n\n            # Train the model\n            mlp_classifier.fit(X_train_tfidf[:50000], y_train_adjusted[:50000])  # Use a larger subset\n            y_pred_mlp = mlp_classifier.predict(X_test_tfidf)\n\n            # Adjust predictions back to the original label scale for reporting\n            y_pred_mlp_original = y_pred_mlp + 1\n\n            # Performance reporting\n            print(f\"MLPClassifier Classification Report for hidden_layer_sizes={hidden_layer_sizes}, activation={activation}, solver={solver}:\")\n            print(classification_report(y_test, y_pred_mlp_original))\n            accuracy = accuracy_score(y_test, y_pred_mlp_original)\n            print(f\"MLPClassifier Accuracy: {accuracy:.4f}\\n\")\n\n            # Check memory usage after each iteration\n            check_memory()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T13:35:19.876704Z","iopub.execute_input":"2025-01-26T13:35:19.877074Z","execution_failed":"2025-01-26T15:12:32.771Z"}},"outputs":[{"name":"stdout","text":"Training MLPClassifier with hidden_layer_sizes=(100,), activation=relu, solver=adam...\nMLPClassifier Classification Report for hidden_layer_sizes=(100,), activation=relu, solver=adam:\n              precision    recall  f1-score   support\n\n           1       0.80      0.81      0.80    180000\n           2       0.81      0.80      0.80    180000\n\n    accuracy                           0.80    360000\n   macro avg       0.80      0.80      0.80    360000\nweighted avg       0.80      0.80      0.80    360000\n\nMLPClassifier Accuracy: 0.8044\n\nMemory usage: 46.6%\nTraining MLPClassifier with hidden_layer_sizes=(100,), activation=relu, solver=sgd...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"MLPClassifier Classification Report for hidden_layer_sizes=(100,), activation=relu, solver=sgd:\n              precision    recall  f1-score   support\n\n           1       0.83      0.81      0.82    180000\n           2       0.81      0.84      0.82    180000\n\n    accuracy                           0.82    360000\n   macro avg       0.82      0.82      0.82    360000\nweighted avg       0.82      0.82      0.82    360000\n\nMLPClassifier Accuracy: 0.8221\n\nMemory usage: 45.9%\nTraining MLPClassifier with hidden_layer_sizes=(100,), activation=tanh, solver=adam...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Naive Bayes and Support Vector Machine","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Naive Bayes with hyperparameter tuning\nprint(\"Naive Bayes: Experimenting with alpha values...\\n\")\nalpha_values = [0.1, 0.5, 1.0, 2.0]\nfor alpha in alpha_values:\n    print(f\"Training Naive Bayes classifier with alpha={alpha}...\")\n    nb_classifier = MultinomialNB(alpha=alpha)\n    nb_classifier.fit(X_train_tfidf, y_train)\n    \n    print(\"Predicting with Naive Bayes...\")\n    y_pred_nb = nb_classifier.predict(X_test_tfidf)\n    \n    print(f\"Naive Bayes Classification Report for alpha={alpha}:\")\n    print(classification_report(y_test, y_pred_nb))\n    accuracy = accuracy_score(y_test, y_pred_nb)\n    print(f\"Naive Bayes Accuracy with alpha={alpha}: {accuracy:.4f}\\n\")\n\n# SVM with hyperparameter tuning\nprint(\"Support Vector Machine: Experimenting with C values...\\n\")\nc_values = [0.1, 0.5, 1.0, 2.0]\nfor c_value in c_values:\n    print(f\"Training Support Vector Machine classifier with C={c_value}...\")\n    svm_classifier = LinearSVC(C=c_value, max_iter=5000)\n    svm_classifier.fit(X_train_tfidf, y_train)\n    \n    print(\"Predicting with SVM...\")\n    y_pred_svm = svm_classifier.predict(X_test_tfidf)\n    \n    print(f\"SVM Classification Report for C={c_value}:\")\n    print(classification_report(y_test, y_pred_svm))\n    accuracy = accuracy_score(y_test, y_pred_svm)\n    print(f\"SVM Accuracy with C={c_value}: {accuracy:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T16:42:13.187581Z","iopub.execute_input":"2025-01-25T16:42:13.188009Z","iopub.status.idle":"2025-01-25T16:49:08.963381Z","shell.execute_reply.started":"2025-01-25T16:42:13.187978Z","shell.execute_reply":"2025-01-25T16:49:08.962505Z"}},"outputs":[{"name":"stdout","text":"Naive Bayes: Experimenting with alpha values...\n\nTraining Naive Bayes classifier with alpha=0.1...\nPredicting with Naive Bayes...\nNaive Bayes Classification Report for alpha=0.1:\n              precision    recall  f1-score   support\n\n           1       0.81      0.79      0.80    180000\n           2       0.80      0.82      0.81    180000\n\n    accuracy                           0.81    360000\n   macro avg       0.81      0.81      0.81    360000\nweighted avg       0.81      0.81      0.81    360000\n\nNaive Bayes Accuracy with alpha=0.1: 0.8051\n\nTraining Naive Bayes classifier with alpha=0.5...\nPredicting with Naive Bayes...\nNaive Bayes Classification Report for alpha=0.5:\n              precision    recall  f1-score   support\n\n           1       0.81      0.79      0.80    180000\n           2       0.80      0.82      0.81    180000\n\n    accuracy                           0.81    360000\n   macro avg       0.81      0.81      0.81    360000\nweighted avg       0.81      0.81      0.81    360000\n\nNaive Bayes Accuracy with alpha=0.5: 0.8051\n\nTraining Naive Bayes classifier with alpha=1.0...\nPredicting with Naive Bayes...\nNaive Bayes Classification Report for alpha=1.0:\n              precision    recall  f1-score   support\n\n           1       0.81      0.79      0.80    180000\n           2       0.80      0.82      0.81    180000\n\n    accuracy                           0.81    360000\n   macro avg       0.81      0.81      0.81    360000\nweighted avg       0.81      0.81      0.81    360000\n\nNaive Bayes Accuracy with alpha=1.0: 0.8051\n\nTraining Naive Bayes classifier with alpha=2.0...\nPredicting with Naive Bayes...\nNaive Bayes Classification Report for alpha=2.0:\n              precision    recall  f1-score   support\n\n           1       0.81      0.79      0.80    180000\n           2       0.80      0.82      0.81    180000\n\n    accuracy                           0.81    360000\n   macro avg       0.81      0.81      0.81    360000\nweighted avg       0.81      0.81      0.81    360000\n\nNaive Bayes Accuracy with alpha=2.0: 0.8051\n\nSupport Vector Machine: Experimenting with C values...\n\nTraining Support Vector Machine classifier with C=0.1...\nPredicting with SVM...\nSVM Classification Report for C=0.1:\n              precision    recall  f1-score   support\n\n           1       0.83      0.83      0.83    180000\n           2       0.83      0.84      0.83    180000\n\n    accuracy                           0.83    360000\n   macro avg       0.83      0.83      0.83    360000\nweighted avg       0.83      0.83      0.83    360000\n\nSVM Accuracy with C=0.1: 0.8328\n\nTraining Support Vector Machine classifier with C=0.5...\nPredicting with SVM...\nSVM Classification Report for C=0.5:\n              precision    recall  f1-score   support\n\n           1       0.83      0.83      0.83    180000\n           2       0.83      0.84      0.83    180000\n\n    accuracy                           0.83    360000\n   macro avg       0.83      0.83      0.83    360000\nweighted avg       0.83      0.83      0.83    360000\n\nSVM Accuracy with C=0.5: 0.8329\n\nTraining Support Vector Machine classifier with C=1.0...\nPredicting with SVM...\nSVM Classification Report for C=1.0:\n              precision    recall  f1-score   support\n\n           1       0.83      0.83      0.83    180000\n           2       0.83      0.84      0.83    180000\n\n    accuracy                           0.83    360000\n   macro avg       0.83      0.83      0.83    360000\nweighted avg       0.83      0.83      0.83    360000\n\nSVM Accuracy with C=1.0: 0.8329\n\nTraining Support Vector Machine classifier with C=2.0...\nPredicting with SVM...\nSVM Classification Report for C=2.0:\n              precision    recall  f1-score   support\n\n           1       0.83      0.83      0.83    180000\n           2       0.83      0.84      0.83    180000\n\n    accuracy                           0.83    360000\n   macro avg       0.83      0.83      0.83    360000\nweighted avg       0.83      0.83      0.83    360000\n\nSVM Accuracy with C=2.0: 0.8329\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Store the results of accuracy for visualization\nnb_accuracies = [0.8057, 0.8057, 0.8057, 0.8057]  # Replace with actual values from your output\nsvm_accuracies = [0.8331, 0.8331, 0.8331, 0.8331]  # Replace with actual values from your output\n\n# Plot Naive Bayes results\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(alpha_values, nb_accuracies, marker='o', color='blue', label='Naive Bayes')\nplt.title(\"Naive Bayes Hyperparameter Tuning\")\nplt.xlabel(\"Alpha Values\")\nplt.ylabel(\"Accuracy\")\nplt.grid(True)\nplt.legend()\n\n# Plot SVM results\nplt.subplot(1, 2, 2)\nplt.plot(c_values, svm_accuracies, marker='o', color='green', label='SVM')\nplt.title(\"SVM Hyperparameter Tuning\")\nplt.xlabel(\"C Values\")\nplt.ylabel(\"Accuracy\")\nplt.grid(True)\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:24:59.538494Z","iopub.execute_input":"2025-01-21T11:24:59.538803Z","iopub.status.idle":"2025-01-21T11:24:59.953651Z","shell.execute_reply.started":"2025-01-21T11:24:59.538777Z","shell.execute_reply":"2025-01-21T11:24:59.952885Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import joblib\n\n# Assume SVM with C=1.0 is the best model (replace with your best parameters)\nbest_svm_classifier = LinearSVC(C=1.0, max_iter=5000)\nbest_svm_classifier.fit(X_train_tfidf, y_train)\n\n# Save the model\njoblib.dump(best_svm_classifier, \"best_svm_model.pkl\")\nprint(\"Best SVM model saved as 'best_svm_model.pkl'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:25:05.908752Z","iopub.execute_input":"2025-01-21T11:25:05.909073Z","iopub.status.idle":"2025-01-21T11:27:09.300513Z","shell.execute_reply.started":"2025-01-21T11:25:05.909043Z","shell.execute_reply":"2025-01-21T11:27:09.299729Z"}},"outputs":[{"name":"stdout","text":"Best SVM model saved as 'best_svm_model.pkl'\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Load the saved model\nloaded_model = joblib.load(\"best_svm_model.pkl\")\n\n# Predict on test data\nnew_predictions = loaded_model.predict(X_test_tfidf)\n\n# Evaluate the model\nprint(\"Classification Report for Best Model:\")\nprint(classification_report(y_test, new_predictions))\n\naccuracy = accuracy_score(y_test, new_predictions)\nprint(f\"Accuracy of Best Model: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:27:09.301647Z","iopub.execute_input":"2025-01-21T11:27:09.301929Z","iopub.status.idle":"2025-01-21T11:27:09.490273Z","shell.execute_reply.started":"2025-01-21T11:27:09.301906Z","shell.execute_reply":"2025-01-21T11:27:09.48952Z"}},"outputs":[{"name":"stdout","text":"Classification Report for Best Model:\n              precision    recall  f1-score   support\n\n           1       0.83      0.83      0.83    180000\n           2       0.83      0.84      0.83    180000\n\n    accuracy                           0.83    360000\n   macro avg       0.83      0.83      0.83    360000\nweighted avg       0.83      0.83      0.83    360000\n\nAccuracy of Best Model: 0.8329\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import spacy\n\n# Load Spacy model for preprocessing\nnlp = spacy.load(\"en_core_web_sm\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:27:09.491524Z","iopub.execute_input":"2025-01-21T11:27:09.491736Z","iopub.status.idle":"2025-01-21T11:27:15.978089Z","shell.execute_reply.started":"2025-01-21T11:27:09.491716Z","shell.execute_reply":"2025-01-21T11:27:15.977382Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# **TESTING WITH UNSEEN DATA** ","metadata":{}},{"cell_type":"code","source":"import spacy\nimport joblib\nimport pandas as pd\n\n# Load Spacy model for preprocessing\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Sample unseen reviews\nunseen_reviews = [\n    \"I absolutely love this product! It's amazing.\",\n    \"The experience was horrible and I regret buying it.\",\n    \"Not bad, but not great either. It's average.\"\n]\n\n# Preprocessing function\ndef preprocess_review(review):\n    return ' '.join([token.lemma_ for token in nlp(review) if token.is_alpha and not token.is_stop])\n\n# Load necessary models and vectorizers\nhash_vectorizer = joblib.load('/kaggle/working/hashing_vectorizer.pkl')  # Corrected file path\nloaded_model = joblib.load('best_svm_model.pkl')\n\n# Preprocess and transform unseen reviews\nunseen_reviews_cleaned = [preprocess_review(review) for review in unseen_reviews]\nunseen_reviews_tfidf = batch_hash_transform(hash_vectorizer, pd.Series(unseen_reviews_cleaned))\n\n# Predict sentiments\nunseen_predictions = loaded_model.predict(unseen_reviews_tfidf)\n\n# Display predictions\nfor review, prediction in zip(unseen_reviews, unseen_predictions):\n    sentiment = \"Positive\" if prediction == 2 else \"Negative\"\n    print(f\"Review: {review}\\nPredicted Sentiment: {sentiment}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:27:15.979052Z","iopub.execute_input":"2025-01-21T11:27:15.979548Z","iopub.status.idle":"2025-01-21T11:27:16.599673Z","shell.execute_reply.started":"2025-01-21T11:27:15.979525Z","shell.execute_reply":"2025-01-21T11:27:16.598913Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 1 / 1\nReview: I absolutely love this product! It's amazing.\nPredicted Sentiment: Positive\n\nReview: The experience was horrible and I regret buying it.\nPredicted Sentiment: Negative\n\nReview: Not bad, but not great either. It's average.\nPredicted Sentiment: Negative\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# **Other Three Models**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T17:05:09.818591Z","iopub.execute_input":"2025-01-25T17:05:09.818937Z","iopub.status.idle":"2025-01-25T17:05:09.823446Z","shell.execute_reply.started":"2025-01-25T17:05:09.818911Z","shell.execute_reply":"2025-01-25T17:05:09.822284Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport gc  # Garbage collector for memory optimization\n\n# Ensure consistent train-test split for hashed data\nX_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n    X_train_tfidf, y_train, test_size=0.2, random_state=42  # 80% training, 20% testing\n)\n\n# Re-map y_train and y_test labels to binary (0 and 1) for binary classification\ny_train_split = y_train_split - 1\ny_test_split = y_test_split - 1\n\n# Display shapes of the datasets\nprint(f\"Training data shape (X_train): {X_train_split.shape}, Labels shape (y_train): {y_train_split.shape}\")\nprint(f\"Testing data shape (X_test): {X_test_split.shape}, Labels shape (y_test): {y_test_split.shape}\\n\")\n\n# Step 1: XGBoost Hyperparameter Tuning with GPU Support\nprint(\"=== XGBoost: Hyperparameter Tuning with GPU Support ===\\n\")\n\n# Define parameter values for tuning\nxgb_params = {\n    'n_estimators': [50, 100, 200],  # Number of trees\n    'learning_rate': [0.01, 0.1, 0.2],  # Step size shrinkage\n    'max_depth': [6, 10, 15],  # Depth of trees\n}\n\n# Perform hyperparameter tuning for XGBoost (GPU version)\nfor n_estimators in xgb_params['n_estimators']:\n    for learning_rate in xgb_params['learning_rate']:\n        for max_depth in xgb_params['max_depth']:\n            print(f\"Training XGBoost: n_estimators={n_estimators}, learning_rate={learning_rate}, max_depth={max_depth} (using GPU)\")\n            \n            # Initialize and train the model with GPU support\n            xgb_classifier = XGBClassifier(\n                n_estimators=n_estimators,\n                learning_rate=learning_rate,\n                max_depth=max_depth,\n                random_state=42,\n                use_label_encoder=False,\n                eval_metric='logloss',\n                tree_method=\"hist\",         # Use hist as the tree method\n                device=\"cuda\",              # Set device to CUDA\n                n_jobs=-1,                  # Use all cores for parallel processing\n                verbosity=1,                # Monitor training process\n                subsample=0.8,              # Use a fraction of data for each tree\n                colsample_bytree=0.8        # Improve memory efficiency\n            )\n            \n            # Fit the model with early stopping and eval set\n            xgb_classifier.fit(\n                X_train_split, \n                y_train_split, \n                eval_set=[(X_test_split, y_test_split)], \n                early_stopping_rounds=10,\n                verbose=False  # Suppress detailed logging\n            )\n            \n            # Predict the test set\n            y_pred_xgb = xgb_classifier.predict(X_test_split)\n            \n            # Display results\n            print(f\"\\nClassification Report (XGBoost, n_estimators={n_estimators}, learning_rate={learning_rate}, max_depth={max_depth}):\")\n            print(classification_report(y_test_split, y_pred_xgb))\n            accuracy = accuracy_score(y_test_split, y_pred_xgb)\n            print(f\"Accuracy: {accuracy:.4f}\\n\")\n            \n            # Clear memory\n            del xgb_classifier, y_pred_xgb\n            gc.collect()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T18:38:43.841636Z","iopub.execute_input":"2025-01-25T18:38:43.841951Z","iopub.status.idle":"2025-01-25T18:38:44.802249Z","shell.execute_reply.started":"2025-01-25T18:38:43.841928Z","shell.execute_reply":"2025-01-25T18:38:44.801062Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1625b827e186>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Ensure consistent train-test split for hashed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m  \u001b[0;31m# 80% training, 20% testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train_tfidf' is not defined"],"ename":"NameError","evalue":"name 'X_train_tfidf' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"print(data.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T16:56:43.508644Z","iopub.execute_input":"2025-01-25T16:56:43.508966Z","iopub.status.idle":"2025-01-25T16:56:43.514173Z","shell.execute_reply.started":"2025-01-25T16:56:43.508941Z","shell.execute_reply":"2025-01-25T16:56:43.513158Z"}},"outputs":[{"name":"stdout","text":"Index(['review', 'label', 'cleaned_review'], dtype='object')\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}